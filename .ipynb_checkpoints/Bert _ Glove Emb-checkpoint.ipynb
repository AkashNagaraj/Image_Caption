{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0627 15:29:36.931845 140172425508480 file_utils.py:41] PyTorch version 1.2.0+cu92 available.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from numpy import savetxt\n",
    "import pickle\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bert Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BERT_emb(text):\n",
    "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "    tokens = torch.tensor([tokenizer.encode(text, add_special_tokens = True)])\n",
    "    model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    embeddings = model(tokens)[0]\n",
    "    return embeddings "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Glove Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Glove_emb(text):\n",
    "    words = []\n",
    "    idx = 0\n",
    "    word_to_idx = {}\n",
    "    glove_path = os.getcwd()\n",
    "    vectors = []\n",
    "\n",
    "    file_ = open(f'{glove_path}/glove.6B.50d.txt', 'rb').readlines()\n",
    "    for l in file_[:300]:\n",
    "        line = l.decode().split()\n",
    "        word = line[0]\n",
    "        words.append(word)\n",
    "        word_to_idx[word] = idx\n",
    "        idx += 1\n",
    "        vect = line[1:]\n",
    "        vectors += vect\n",
    "        \n",
    "    np_vectors = np.reshape(np.asarray(vectors, dtype=np.float), (-1,50), 'C')\n",
    "    pickle.dump(np_vectors, open(f'{glove_path}/6B.50_data.pkl', 'wb'))\n",
    "    pickle.dump(words, open(f'{glove_path}/6B.50_words.pkl', 'wb'))\n",
    "    pickle.dump(word_to_idx, open(f'{glove_path}/6B.50_idx.pkl', 'wb'))\n",
    "    #print('The string : {} has vector : {}'.format(words[0], np_vectors[0]))\n",
    "    vectors = pickle.load(open(f'{glove_path}/6B.50_data.pkl', 'rb'))\n",
    "    words = pickle.load(open(f'{glove_path}/6B.50_words.pkl', 'rb'))\n",
    "    word2idx = pickle.load(open(f'{glove_path}/6B.50_idx.pkl', 'rb'))\n",
    "\n",
    "    glove = {w: vectors[word2idx[w]] for w in words}\n",
    "    tokens = text.lower().split()\n",
    "    glove_tokens = torch.tensor([glove[val] for val in tokens], dtype = torch.long)\n",
    "    return glove_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check(G,B,sent_len):\n",
    "    n = int(np.ceil(B.shape[2]/sent_len))\n",
    "    B_new = torch.zeros(9,n*sent_len)\n",
    "    B_new[:,:B.shape[2]] = B[0]\n",
    "    print('Glove : {}'.format(G.shape))\n",
    "    print('BERT : {}'.format(B_new.shape))\n",
    "    return B_new, G"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feedforward(torch.nn.Module):\n",
    "        def __init__(self, input_size, hidden_size):\n",
    "            super(Feedforward, self).__init__()\n",
    "            self.input_size = input_size\n",
    "            self.hidden_size  = hidden_size\n",
    "            self.fc1 = torch.nn.Linear(770, 128)\n",
    "            self.relu = torch.nn.ReLU()\n",
    "            self.fc2 = torch.nn.Linear(128, 50)\n",
    "            self.fc3 = torch.nn.Linear(50, 10)\n",
    "            self.sigmoid = torch.nn.Sigmoid()        \n",
    "        \n",
    "        def forward(self, x):\n",
    "            hidden = self.fc1(x)\n",
    "            relu = self.relu(hidden)\n",
    "            output = self.fc2(relu)\n",
    "            output = self.relu(self.fc3(output))\n",
    "            output = self.sigmoid(output)\n",
    "            return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,Y):\n",
    "    #X = torch.FloatTensor(np.random.randn(9,770))\n",
    "    #Y = torch.FloatTensor(np.random.randn(9,10))\n",
    "\n",
    "    model1 = Feedforward(128,128) #(input, hidden)\n",
    "    val = model1(X)\n",
    "\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    text = \"Top university members found help in history\"\n",
    "    read_text()\n",
    "    \"\"\"\n",
    "    B = BERT_emb(text)\n",
    "    G = Glove_emb(text)\n",
    "    X, Y = check(G,B,G.shape[0])\n",
    "    X, Y = X.type(torch.FloatTensor), Y.type(torch.FloatTensor)\n",
    "    output = forward(X, Y)\n",
    "    print(output.shape)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0626 17:08:17.049924 140711821899392 tokenization_utils.py:504] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/akashnagaraj/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "I0626 17:08:17.318119 140711821899392 configuration_utils.py:283] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/akashnagaraj/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "I0626 17:08:17.320925 140711821899392 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0626 17:08:17.332043 140711821899392 modeling_utils.py:507] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /home/akashnagaraj/.cache/torch/transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
